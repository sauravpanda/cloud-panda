RAG Pipeline
The RAG (Retrieve-And-Generate) Pipeline is responsible for retrieving relevant documents based on a query and generating a response using the retrieved documents as context. It transforms the query, searches for relevant documents, reranks the results, constructs a context, and generates a completion.

Basic RAG Pipeline
The BasicRAGPipeline is an implementation of the RAGPipeline abstract base class. It provides a straightforward way to perform document retrieval and generation using a specified language model, vector database, and embedding model.

Initialization
The BasicRAGPipeline is initialized with the following parameters:

llm: An instance of LLMProvider for generating completions.
db: An instance of VectorDBProvider for searching and retrieving documents.
embedding_model: The name of the embedding model to use.
embeddings_provider: An instance of OpenAIEmbeddingProvider for generating embeddings.
prompt_provider (optional): An instance of PromptProvider for providing prompts (default is BasicPromptProvider).
logging_connection (optional): An instance of LoggingDatabaseConnection for logging.
Pipeline Execution
The run method executes the RAG pipeline. It takes the following parameters:

query: The input query for retrieving relevant documents.
filters (optional): Filters to apply during document retrieval (default is an empty dictionary).
limit (optional): The maximum number of documents to retrieve (default is 10).
search_only (optional): A flag indicating whether to perform only document retrieval without generating a completion (default is False).
generation_config (optional): An instance of GenerationConfig specifying the parameters for generating completions (default is None).
The pipeline performs the following steps:

Initializes the pipeline by calling the initialize_pipeline method.
Transforms the query using the transform_query method.
Searches for relevant documents using the search method.
If search_only is True, returns the retrieved documents as RAGPipelineOutput.
Constructs a context from the retrieved documents using the construct_context method.
Constructs a prompt using the construct_prompt method.
If generation_config.stream is False, generates a completion using the generate_completion method and returns the RAGPipelineOutput.
If generation_config.stream is True, streams the completion using the _stream_run method.
Query Transformation
The transform_query method transforms the input query before retrieval. It can be overridden to implement custom query transformation logic.

Document Retrieval
The search method retrieves relevant documents from the vector database using the transformed query. It uses the specified embedding model and embeddings provider to generate embeddings for the query and performs a similarity search in the database.

Result Reranking
The rerank_results method reranks the retrieved documents based on relevance or other criteria. It can be overridden to implement custom reranking logic.

Context Construction
The construct_context method constructs a context from the reranked documents. It formats the results into a human-readable string using the _format_results method.

Prompt Construction
The construct_prompt method constructs a prompt for generating completions based on the query and context. It uses the specified prompt provider to retrieve the appropriate prompt template.

Completion Generation
The generate_completion method generates a completion based on the constructed prompt using the specified language model. It returns the generated completion as a ChatCompletion object.

Custom RAG Pipeline
The CustomRAGPipeline is a custom implementation of the RAGPipeline that inherits from the RAGPipeline base class. It demonstrates how to modify various aspects of the pipeline, such as query transformation, result reranking, and result formatting.

"""
A simple example to demonstrate a custom RAG pipeline.
"""
import logging
from typing import Optional
 
from r2r.core import (
    LLMProvider,
    LoggingDatabaseConnection,
    PromptProvider,
    RAGPipeline,
    VectorDBProvider,
    VectorSearchResult,
    log_execution_to_db,
)
from r2r.embeddings import OpenAIEmbeddingProvider
from r2r.pipelines import BasicPromptProvider
 
logger = logging.getLogger(__name__)
 
 
class CustomRAGPipeline(RAGPipeline):
    def __init__(
        self,
        llm: LLMProvider,
        db: VectorDBProvider,
        embedding_model: str,
        embeddings_provider: OpenAIEmbeddingProvider,
        prompt_provider: Optional[PromptProvider] = None,
        logging_connection: Optional[LoggingDatabaseConnection] = None,
    ) -> None:
        if not prompt_provider:
            prompt_provider = BasicPromptProvider()
        self.prompt_provider = prompt_provider
 
        super().__init__(
            llm,
            prompt_provider=prompt_provider,
            logging_connection=logging_connection,
        )
        self.embedding_model = embedding_model
        self.embeddings_provider = embeddings_provider
        self.db = db
        self.pipeline_run_info = None
 
    def transform_query(self, query: str) -> str:
        """
        Transforms the input query by adding a prefix.
        """
        self._check_pipeline_initialized()
        return f"Custom query: {query}"
 
    @log_execution_to_db
    def search(
        self,
        transformed_query: str,
        filters: dict,
        limit: int,
        *args,
        **kwargs,
    ) -> list[VectorSearchResult]:
        """
        Searches the vector database with the transformed query.
        """
        logger.debug(f"Retrieving results for query: {transformed_query}")
        self._check_pipeline_initialized()
        results = self.db.search(
            query_vector=self.embeddings_provider.get_embedding(
                transformed_query,
                self.embedding_model,
            ),
            filters=filters,
            limit=limit,
        )
        logger.debug(f"Retrieved the raw results shown:\n{results}\n")
        return results
 
    def rerank_results(
        self, results: list[VectorSearchResult]
    ) -> list[VectorSearchResult]:
        """
        Reranks the retrieved documents based on custom logic.
        """
        self._check_pipeline_initialized()
        # Custom reranking logic - Reverse the order of results
        return list(reversed(results))
 
    def _format_results(self, results: list[VectorSearchResult]) -> str:
        """
        Formats the reranked results into a numbered list.
        """
        formatted_results = [
            f"{i+1}. {result.metadata['text']}"
            for i, result in enumerate(results)
        ]
        return "\n".join(formatted_results)
In this example, the CustomRAGPipeline overrides the following methods:

transform_query: Adds a custom prefix to the input query.
rerank_results: Implements custom reranking logic by reversing the order of the retrieved results.
_format_results: Formats the reranked results into a numbered list.
The rest of the pipeline execution remains the same as the base implementation.

Passing the Custom RAG Pipeline to the Factory
To use the CustomRAGPipeline with the E2EPipelineFactory, you can pass it when creating the pipeline:

from r2r.main import E2EPipelineFactory
from my_custom_pipeline import CustomRAGPipeline
 
app = E2EPipelineFactory.create_pipeline(
    config=config,
    rag_pipeline_impl=CustomRAGPipeline,
)
By passing the CustomRAGPipeline to the create_pipeline method using the rag_pipeline_impl parameter, the factory will use the custom pipeline instead of the default BasicRAGPipeline.

That's it! You now have a custom RAG pipeline that demonstrates how to modify various aspects of the pipeline and can be passed to the E2EPipelineFactory for use in the end-to-end pipeline.