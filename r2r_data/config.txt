During the example pipeline creation a default config.json is loaded and passed to the pipeline. It provides settings for the following services:

Vector Database provider
LLM settings
Embedding settings
Parsing logic
Evaluation provider
and more.
The default values for the config are shown below.

{
  "vector_database": {
    "provider": "local",
    "collection_name": "demo-v1-test"
  },
  "evals": {
    "provider": "deepeval",
    "frequency": 0.25
  },
  "embedding": {
    "provider": "openai",
    "model": "text-embedding-3-small",
    "dimension": 1536,
    "batch_size": 32
  },
  "text_splitter": {
    "chunk_size": 512,
    "chunk_overlap": 20
  },
  "language_model": {
    "provider": "litellm",
    "model": "gpt-4-0125-preview",
    "temperature": 0.1,
    "top_p": 0.9,
    "top_k": 128,
    "max_tokens_to_sample": 1024,
    "do_stream": false
  },
  "logging": {
    "provider": "local",
    "level": "INFO",
    "name": "r2r",
    "database": "demo_logs_v1"
  }
}
To launch the default pipeline with your own config, you may run with the following

 
class E2EPipelineFactory:
    ...
    app = E2EPipelineFactory.create_pipeline(
        # override with your own config.json
        config_path=my_config.json,
    )
